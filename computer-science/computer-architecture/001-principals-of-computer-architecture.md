---
title: 컴퓨터 구조의 7가지 원칙
parent: 컴퓨터 구조
nav_order: 1
date: 2025-01-23
excerpt: 컴퓨터 구조의 7가지 원칙은 컴퓨터 시스템의 설계와 발전에 크게 영향을 미친 기본 개념들을 정리한 틀이다.
permalink: /computer-architecture/principals-of-computer-architecture
---

## Table of contents
{: .no_toc .text-delta }

- TOC
{:toc}

---

## 컴퓨터 구조의 7가지 원칙이란?

**컴퓨터 구조의 7가지 원칙**은 컴퓨터 시스템의 설계와 발전에 크게 영향을 미친 기본 개념들을 정리한 틀이다. 이 아이디어들은 다음과 같다.

1. **추상화**(**Abstraction**): 복잡한 시스템을 관리하기 쉬운 구성 요소로 나누어 단순화하는 것.
2. **자주 생기는 일을 빠르게(Common Case Fast)**: 자주 실행되는 작업이나 시나리오의 성능을 최적화하는 것.
3. **병렬성(Parallelism)**: 처리 속도를 향상시키기 위해 여러 작업을 동시에 수행하는 것.
4. **파이프라이닝(Pipelining)**: 작업을 여러 단계로 나누어 동시에 처리함으로써 성능과 효율성을 향상시키는 것.
5. **예측(Prediction)**: 분기 예측과 같은 기술을 사용하여 미래의 작업을 예상하고 지연을 줄이는 것.
6. **메모리 계층 구조(Memory Hierarchy)**: 속도와 용량의 균형을 맞추기 위해 캐시와 다양한 저장 유형을 활용하여 메모리 시스템을 구조화하는 것.
7. **신용도(Dependability)**: 시스템의 신뢰성과 결함 허용성을 보장하는 것.

이 아이디어들은 현대 컴퓨터 구조의 기초를 형성하며, 효율적이고 강력한 컴퓨팅 시스템 개발을 안내한다.

---

## 추상화

**추상화**(**Abstraction**)는 복잡한 시스템을 단순화하는 과정으로, 구현의 복잡한 세부 사항을 숨기고 사용자나 프로그래머에게 필요한 기능만을 드러내는 것을 의미한다. 이 개념은 개발자들이 하드웨어와 소프트웨어 구성 요소와 더 높은 수준에서 상호작용할 수 있게 하며, 기본적인 복잡성을 이해할 필요가 없도록 한다. 예를 들어, 컴퓨터 구조에서 추상화는 고급 프로그래밍 언어의 사용에서 나타나는데, 이는 프로그래머가 기계의 명령어 집합이나 메모리 관리의 세부 사항을 신경 쓰지 않고도 코드를 작성할 수 있게 해준다. 또한, 운영 체제나 가상 머신과 같은 추상화 계층은 자원을 관리하고 하드웨어와 소프트웨어 간의 통신을 촉진하는 방법을 제공하여, 더 효율적인 설계와 쉬운 유지보수, 그리고 다양한 시스템 간의 향상된 이식성을 가능하게 한다.

---

## 자주 생기는 일을 빠르게

**자주 생기는 일을 빠르게**(**Common Case Fast**)는 프로그램에서 가장 자주 실행되는 경로 또는 작업의 성능을 최적화하는 것을 우선시하는 설계 원칙을 의미한다. 이 접근법은 드물게 발생하는 엣지 케이스를 처리해야 할 필요성이 있을 수 있지만, 대부분의 실행 시간은 일반적인 시나리오에 소요된다는 것을 인식한다. 이러한 자주 생기는 일을 가능한 한 효율적으로 만들기 위해 캐싱, 파이프라이닝, 분기 예측과 같은 기술을 활용함으로써 아키텍트는 전체 시스템 성능을 크게 향상시킬 수 있다. 이 원칙은 프로세서, 메모리 계층 구조 및 명령어 집합 설계에서 매우 중요하며, 시스템이 정상적인 작업 부하에서 효율적으로 작동하도록 보장하여 사용자 경험과 애플리케이션 반응성을 개선하는 데 도움을 준다.

---

## 병렬성(Parallelism)

**병렬성**(**Parallelism**)은 컴퓨터 시스템이 여러 작업이나 연산을 동시에 수행할 수 있는 능력을 의미하며, 이를 통해 성능과 효율성을 높일 수 있다. 이는 여러 프로세서(멀티코어 또는 멀티프로세서 시스템), 벡터 프로세서, 많은 연산을 병렬로 처리할 수 있는 GPU(그래픽 처리 장치)와 같은 특수 하드웨어를 통해 이루어질 수 있다. 병렬성에는 여러 수준이 있으며, 그 중 하나는 명령어 수준 병렬성(Instruction Level Parallelism, ILP)으로, 이는 단일 프로세서 내에서 여러 명령어가 동시에 실행되는 상황을 말한다. 또 다른 수준은 작업 수준 병렬성(Task Level Parallelism, TLP)으로, 이는 서로 다른 작업이나 프로세스가 여러 프로세서에서 동시에 실행되는 상황을 의미한다. 병렬성을 활용함으로써 컴퓨터 시스템은 복잡한 계산의 실행 시간을 크게 줄이고 전체 처리량을 향상시킬 수 있으며, 이는 현대 컴퓨팅 설계와 성능 최적화의 중요한 요소가 된다. 

---

## 파이프라이닝

**파이프라이닝**(**Pipelining**)은 성능과 효율성을 향상시키기 위해 컴퓨터 구조와 처리 시스템에서 일반적으로 사용되는 특정 형태의 병렬 처리 방식이다. 이는 작업을 일련의 개별 단계로 나누는 것을 포함하며, 각 단계는 작업의 일부를 완료하고 그 결과를 다음 단계로 전달한다. 이렇게 하면 여러 명령어나 데이터를 서로 다른 완료 단계에서 동시에 처리할 수 있어, 제조업의 조립 라인과 비슷하다. 예를 들어, CPU에서는 명령어를 가져오고, 디코딩하며, 실행하고, 결과를 쓰는 과정이 병렬로 발생할 수 있으며, 각 단계는 동시에 서로 다른 명령어에 대해 작업을 수행한다. 이러한 작업의 중첩은 유휴 시간을 줄이고 처리량을 증가시켜, 파이프라이닝이 전체 처리 속도를 향상시키는 효과적인 전략이 되도록 한다.

---

## 예측

**예측**(**Prediction**)은 프로세서의 성능을 향상시키기 위해 미래의 사건이나 데이터 접근 패턴을 예측하는 기술을 의미한다. 여기에는 분기 예측이 포함되는데, 이는 프로세서가 조건부 연산의 결과를 추측하여 실제 결과를 기다리는 데서 발생하는 지연을 최소화하는 방법이다. 또한 데이터 프리패칭이 있는데, 이는 CPU가 명시적으로 요청하기 전에 데이터를 캐시에 미리 로드하는 과정을 포함한다. 이러한 예측 메커니즘은 파이프라인을 명령어와 데이터로 가득 채워 지연 시간을 줄이고 명령어 처리량을 개선하여 컴퓨팅 시스템의 전반적인 효율성을 최적화하는 것을 목표로 한다. 프로세서가 점점 더 복잡해짐에 따라, 효과적인 예측 전략은 현대 컴퓨팅 환경에서 높은 성능을 유지하는 데 매우 중요하다.

---

## 메모리 계층구조

**메모리 계층구조**(**Memory Hierarchy**)는 속도, 크기 및 비용이 다른 다양한 유형의 메모리 저장 장치로 구성된 구조화된 배열을 의미하며, 이는 컴퓨터 시스템의 성능을 최적화하기 위해 설계되었다. 계층 구조의 최상위에는 CPU 레지스터와 캐시 메모리(L1, L2, L3)와 같은 가장 빠르고 비싼 메모리가 위치해 있으며, 이는 자주 사용되는 데이터에 신속하게 접근할 수 있도록 한다. 그 아래에는 더 크지만 느린 주 메모리(RAM)가 있으며, 그 다음에는 SSD와 HDD와 같은 보조 저장 장치가 위치해 있는데, 이는 더 많은 용량을 제공하지만 접근 속도가 현저히 느리다. 마지막으로, 자기 테이프와 같은 제3의 저장 장치는 아카이브 용도로 사용된다. 이러한 계층적 구조는 시스템이 속도와 비용을 균형 있게 조절할 수 있도록 하여, 가장 중요한 데이터에 쉽게 접근할 수 있게 하면서도 더 많은 양의 데이터는 느리고 경제적인 방식으로 저장할 수 있게 한다. 이 계층 구조를 효과적으로 사용하는 것은 컴퓨팅 작업에서 높은 성능을 달성하는 데 매우 중요하다. 

---

## 신용도

**신용도**(**Dependability**)는 컴퓨터 시스템의 신뢰성, 가용성, 안전성 및 유지 관리 용이성을 의미한다. 이는 시스템이 미리 정의된 조건에서 특정 기간 동안 의도된 기능을 수행할 수 있는 능력을 포함한다. 신용도는 항공우주, 의료 기기, 자동차 시스템과 같은 안전이 중요한 시스템에서 특히 중요하다. 이러한 시스템에서의 실패는 심각한 결과를 초래할 수 있다. 높은 신용도를 달성하기 위해 컴퓨터 구조는 종종 중복성, 결함 허용, 오류 탐지 및 수정 메커니즘, 그리고 철저한 테스트 및 검증 과정을 포함한다. 신용도의 목표는 시스템이 결함이나 예상치 못한 조건이 존재하더라도 올바르게 작동할 수 있도록 보장하는 것이며, 이를 통해 성능과 무결성에 대한 신뢰를 구축하는 것이다.

---

## 무어의 법칙<sup>(제외됨)</sup>

**무어의 법칙**(**Moore's Law**)은 고든 무어(Gordon Moore)가 1965년에 제안한 관찰로, 마이크로칩의 트랜지스터 수가 약 2년마다 두 배로 증가한다는 내용을 포함하고 있다. 이는 컴퓨팅 파워의 기하급수적인 증가와 상대적인 비용의 감소로 이어진다. 이러한 추세는 컴퓨터 구조에 상당한 영향을 미쳐 성능, 효율성 및 전자 기기의 소형화에 대한 발전을 이끌어왔다. 트랜지스터가 작아지고 더 밀집하게 배치됨에 따라, 더 복잡하고 강력한 프로세서를 가능하게 하여 더 빠르고 능력 있는 컴퓨터의 개발을 촉진한다. 그러나 물리적 및 경제적 한계에 다가감에 따라 무어의 법칙의 지속 가능성에 대한 논의가 이루어지고 있으며, 연구자들은 미래의 성능 향상을 지속하기 위해 대체 기술과 구조를 탐색하고 있다. 
